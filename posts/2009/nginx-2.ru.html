<html><body><div dir="ltr" style="text-align: left;">Данная статья была опубликована в электронном приложением к журналу "<a href="http://www.samag.ru/">Системный администратор</a>"- "<a href="http://osa.samag.ru/">Open Source #042</a>"<br><br><a href="http://blog-ru.greenmice.info/2013/04/nginx-1.html">В первой части</a> статьи я рассказал о базовых и наиболее часто применяемых возможностях nginx. Однако это малая часть того, что можно сделать с nginx. Во второй части своей статьи я расскажу о некоторых более продвинутых возможностях, которые используются в крупных и высоконагруженых проектах.<br><br><h2>Failover и балансировка</h2>Крупные проекты редко состоят из одного сервера приложений. Часто их два или больше, и возникает задача балансировки клиентов по этим серверам, а также выполнения failover — необходимо чтобы выход из строя одного из серверов не был заметен для клиентов.<br>Простейший способ рещить эту задачу — dns round-robin, т.е. назначение доменному имени нескольких ip-адресов. Но это решение имеет ряд недостатков, и гораздо лучше выглядит решение балансировки запросов по бакендам на фронтенде nginx. В конфигурационном файле выглядит это примерно так:<br><br><pre class="brush: c"># объявляем upstream — список бакендов<br>upstream  backend  {<br>  # перечисляем dns-имена или ip-адреса серверов и их «вес»<br>  server   web1                 weight=5;<br>  server   1.2.3.4:8080         weight=5;<br>  # а так можно подключаться к бакенду через unix-сокет<br>  server   unix:/tmp/backend3   weight=1;<br>}<br># конфигурация виртуального сервера<br>server {<br>  listen &lt;...&gt;;<br>  server_name myserver.com;<br>  # отправляем все запросы из локейшена / в апстрим<br>  location / {<br>    proxy_pass  http://backend;<br>  }<br>}<br></pre><br>Запросы, приходящие к nginx, распределяются по бакендам соответственно указаному весу. Кроме того, можно сделать так, чтобы запросы с одних и тех же IP-адресов отправлялись на одни и те же серверы (для этого в upstream нужно указать директиву ip_hash). Так можно решить проблему с сессиями, но все же лучше найти какой-нибудь способ их репликации или (что еще лучше) использовать <a href="http://ru.wikipedia.org/wiki/REST">RESTful-подход</a>.<br>В случае, если один из серверов откажется принимать соединения или соединение к нему отвалится по таймауту, он на некоторое время будет исключен из upstream.<br><br><a name="more"></a><br><br><h2>Оптимизация nginx</h2><br><h3>1. Увеличение количества и объема буферов</h3><br>Для хранения принятых запросов и еще не отданных ответов nginx использует буферы в памяти, а если запрос или ответ не помещается в них, nginx записывает его во временный файл (и пишет при этом предупреждение в log-файл). Поэтому необходимо установить такие размеры, чтобы в большинстве случаев не требовалось обращаться к временному файлу, а с другой стороны — чтобы буферы не использовали слишком много памяти.<br><br>Для этого используются следующие параметры:<br><b>client_body_buffer_size</b> (по умолчанию: 8k/16k — в зависимости от архитектуры) — задает размер буфера для чтения тела запроса клиента. Обычно стандартного значения хватает, его требуется повышать, только если ваше приложение устанавливает огромные cookies.<br><b>proxy_buffer_size</b> (по умолчанию: 4k/8k) — задает размер буфера, в который будет читаться первая часть ответа, получаемого от проксируемого сервера. В этой части ответа находится, как правило, небольшой заголовок ответа. Стандартного значения обычно хватает.<br><b>proxy_buffers</b> (по умолчанию: 8 4k/8k) — задает число и размер буферов для одного соединения, в которые будет читаться ответ, получаемый от проксируемого сервера. Установите этот параметр так, чтобы большинство ответов от бэкенда помещалось в буферы.<br><br><h3>2. Механизмы обработки соединений</h3><br>Есть одна тонкость, касающаяся механизма обработки соединений, а именно — способ получения информации о событиях на сокетах. Существуют следующие методы:<br><br><ul><li>select — стандартный метод. На большой нагрузке сильно нагружает процессор.</li><li>poll — стандартный метод. Также сильно нагружает процессор.</li><li>kqueue — эффективный метод, используемый в операционных системах FreeBSD 4.1+, OpenBSD 2.9+, NetBSD 2.0 и Mac OS X. На 2-процессорных машинах под управлением Mac OS X использование kqueue может привести к kernel panic.</li><li>epoll — эффективный метод, используемый в Linux 2.6+. В некоторых старых дистрибутивах есть патчи для поддержки epoll ядром 2.4.</li><li>rtsig — real time signals, эффективный метод, используемый в Linux 2.2.19+. При больших количествах одновременных соединений (более 1024) с ним могут быть проблемы (их можно обойти, но на мой взгляд, лучше с этим не связываться).</li><li>/dev/poll — эффективный метод, используемый в Solaris 7 11/99+, HP/UX 11.22+ (eventport), IRIX 6.5.15+ и Tru64 UNIX 5.1A+.</li></ul><br>При компиляции nginx автоматически выбирается максимально эффективный найденый метод, однако скрипту configure можно насильно указать какой метод использовать. Если вы решили сделать это, то лучше использовать такие методы:<br>Linux 2.6: epoll;<br>FreeBSD: kqueue;<br>Solaris, HP/UX и другие: /dev/poll;<br>Linux 2.4 и 2.2: rtsig, не рекомендуется при больших нагрузках.<br><br><br><h3><br>Включение gzip позволяет сжимать ответ, отправляемый клиенту, что положительно сказывается на удовлетворенности пользователя, но требует больше времени CPU. Gzip включается директивой gzip (on|off). Кроме того, стоит обратить на следующие важные директивы модуля gzip:<br><br><b>gzip_comp_level</b> 1..9 — устанавливает уровень сжатия. Опытным путем выявлено, что оптимальные значения лежат в промежутке от 3 до 5, большие значения дают маленький выигрыш, но создают существенно большую нагрузку на процессор, меньшие — дают слишком маленький коэффициент сжатия.<br><b>gzip_min_length</b> (по умолчанию, 0) — минимальный размер ответа, который будет сжиматься. Имеет смысл поставить этот параметр в 1024, чтобы слишком малеьнике файлы не сжимались (т.к. эффективность этого будет мала).<br><b>gzip_types</b> mime-тип [mime-тип ...] - разрешает сжатие ответа методом gzip для указанных MIME-типов в дополнение к "text/html". "text/html" сжимается всегда. Имеет смысл добавить такие mime-типы как text/css, text/javascript и подобные. Разумеется, сжимать gif, jpg и прочие уже компрессированые форматы не имеет смысла.<br><br>Кроме того, существует модуль gzip_static, который позволяет раздавать уже сжатые статические файлы. В конфирурационном файле это выглядит так:<br><br><pre class="brush: c">location /files/ {<br>  gzip on;<br>  gzip_min_length 1024;<br>  gzip_types text/css text/javascript;<br>  gzip_comp_level 5;<br>  gzip_static on;<br>}<br></pre><br>При использовании такой конфигурации в случае запроса «/files/test.html» nginx будет проверять наличие «/files/test.html.gz», и, если этот файл существует и дата его последнего изменения больше, чем дата последнего изменения файла test.html, будет отдан уже сжатый файл, что сохранит ресурсы процессора, которые потребовались бы для сжатия оригинального файла.<br><br></h3><h3>Оптимизация приложений</h3><br>Существует очень полезный трюк, который позволяет указать разработчикам приложений, какие страницы нужно оптимизировать в первую очередь. Для этого потребуется в конфиге nginx указать новый формат лога:<br><br><pre class="brush: c">log_format  my_combined  '$remote_addr - $remote_user [$time_local] '<br>    '"$request" $status $body_bytes_sent '<br>    '"$http_referer" "$http_user_agent" '<br>    '$upstream_response_time "$host"'<br><br>access_log /var/log/nginx/access_log my_combined;<br></pre><br>Переменная $upstream_response_time содержит время ответа бэкенда, поэтому в лог попадает время обработки каждого запроса бэкендом. Далее понадобятся два скрипта:<br><br>1. /usr/local/bin/url_stats_report.sh:<br><br><pre class="brush: bash">#!/bin/sh<br><br>echo "=== Requests which took most of the time ===" &gt; /tmp/report.txt<br>echo "overall time - number of requests - average time - url" &gt;&gt; /tmp/report.txt<br><br>cat /var/log/nginx/*access.log | /usr/local/bin/url_stats.py &gt;&gt; /tmp/report.txt<br>cat /tmp/report.txt | mail -s "url performance report" root<br></pre><br>2. /usr/local/bin/url_stats.py:<br><br><pre class="brush: python">#!/usr/bin/env python<br><br>import sys<br><br>urls = {}<br><br>try:<br>    while 1:<br>        line = raw_input()<br>        line_arr = line.split(" ")<br>        try:<br>            host = line_arr[-1]<br>            host = host[1:]<br>            host = host[:-1]<br>            url = line_arr[6]<br>            t = float(line_arr[-2])<br>            #print host, url, t<br><br>            try:<br>                urls[host + url] = (urls[host + url][0] + t, urls[host + url][1] + 1)<br>            except KeyError, e:<br>                urls[host + url] = (t, 1)<br>        except ValueError, e:<br>            pass<br><br><br>except EOFError, e:<br>   pass<br><br>def sort_by_value(d):<br>    """ Returns the keys of dictionary d sorted by their values """<br>    items=d.items()<br>    backitems=[ [v[1],v[0]] for v in items]<br>    backitems.sort(reverse=True)<br>    return [backitems[i][1] for i in range(0,len(backitems))]<br><br>if (len(sys.argv) &gt; 1):<br>    f = open(sys.argv[1], 'r')<br>    for k in f.readlines():<br>        k = k.strip()<br>        try:<br>             print urls[k][0], urls[k][1], urls[k][0] / urls[k][1], k<br>        except:<br>             print 0, 0, k<br>else:<br>    i = 0<br>    for k in sort_by_value(urls):<br>        print urls[k][0], urls[k][1], urls[k][0] / urls[k][1],  k<br>        i += 1<br>        if i &gt; 100: break<br></pre><br>Они не идеальны, но задачу выполняют: запуская /usr/local/bin/url_stats_report.sh (например, в postrotate утилиты logrotate), вы получаете наглядную картину, какие запросы занимают большую часть времени бэкенда.<br><br><h2>Кеширование</h2>Незадолго до выхода этой статьи, Игорь Сысоев выпустил версию nginx 0.7.44 с экспериментальной поддержкой кеширования. Из-за большого количества багов, за которкое время было выпущено несколько версий, и в настоящее время последняя версия — 0.7.50 уже достаточно хорошо (хотя и не идеально) работает с кешированием.<br>Однако это все еще экспериментальная функция, но я решил рассказать о ней, т.к. ее одень давно ждали многое администраторы, да и лично для меня она очень полезна.<br>Сейчас nginx умеет кешировать на диске ответы от http и fastcgi запросов на бакенды, указывать ключ для кеширования, учитывать заголовки "X-Accel-Expires", "Expires" и "Cache-Control" и вручную устанавливать максимальное время жизни объекта в кеше.<br>Обслуживанием кеша (очиста старых файлов, наблюдение за размером и т.п.) занимается специальный процесс cache manager. Положительной особенностью реализации является то, что при старте nginx cache manager начинает проверку кеша в фоне, благодаря чему nginx не делает то что называется «дает сквида», т.е. он не висит несколько минут проверяя кеш перед стартом.<br>Я намеренно не указываю пример конфигурации, т.к. во-первых директивы могут еще поменяться, а во-вторых нужно глубокое понимание механизма кеширования, что требует вдумчивого чтения документации (http://sysoev.ru/nginx/docs/http/ngx_http_proxy_module.html#proxy_cache) и архивов рассылки nginx-ru.<br><br><h2>За кадром</h2><br>В статье освещена лишь та часть возможностей nginx, которыми я пользуюсь чаще всего. За пределами рассказа остались такие вопросы, как поддержка SSI, работа с memcached, экспериментальный встроенный Perl и сторонние модули, реализующие дополнительную функциональность.</div></body></html>
